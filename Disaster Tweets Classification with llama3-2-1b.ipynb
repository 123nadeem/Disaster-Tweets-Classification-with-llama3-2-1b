{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":120000,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":100931,"modelId":121027}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nfrom IPython.display import clear_output\n!pip install peft==0.8.2\n!pip install bitsandbytes==0.42.0\n!pip install accelerate==0.34.2\n!pip install datasets==2.16.1\n!pip install GPUtil\n!pip install transformers==4.43.1\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T17:54:14.622080Z","iopub.execute_input":"2024-10-16T17:54:14.622741Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting peft==0.8.2\n  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.8.2) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.8.2) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.8.2) (0.20.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mCollecting bitsandbytes==0.42.0\n  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.14.1)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes==0.42.0) (1.26.4)\nDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nimport os\nfrom transformers import set_seed\n\nSEED = 123\nset_seed(SEED)\n\nwarnings.filterwarnings('ignore')\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nINPUT_DIR = '/kaggle/input/nlp-getting-started/'\n\nDIR = '/kaggle/working/'\n\nNUM_WORKERS = os.cpu_count()\nNUM_CLASSES = 2\n\nEPOCHS,R,LORA_ALPHA,LORA_DROPOUT = 5,64,32,0.1\nBATCH_SIZE = 8\n\nMODEL_ID = '/kaggle/input/llama-3.2/transformers/1b/1'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load\n\ndataset = load_dataset(\n    'csv', data_files=f'{INPUT_DIR}train.csv',\n)\n\ndataset['test'] = dataset['train']\n\ndataset = dataset.remove_columns(['id', 'keyword', 'location'])\ndataset = dataset.rename_column(\"target\", \"label\")\n\nprint(dataset, dataset.keys())\ndataset[\"train\"][0], dataset['test'][0], dataset['train'][:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\ntrain_len, test_len = len(dataset['train']), len(dataset['test'])\n\ntrain_dataset_label_counts = Counter(dataset['train']['label'])\ntest_dataset_label_counts = Counter(dataset['test']['label'])\n\nprint(f\"Train dataset: {train_len} samples, {train_dataset_label_counts}\")\nprint(f\"Test dataset: {test_len} samples, {test_dataset_label_counts}\")\n\ntest_majority_class = test_dataset_label_counts.most_common(1)[0]\n\nbaseline_accuracy = test_majority_class[1] / test_len\n\nprint(f\"Baseline accuracy: {baseline_accuracy:.2%}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\nprint(tokenizer.padding_side, tokenizer.pad_token)\ntokenizer.pad_token = tokenizer.eos_token\nprint(tokenizer.padding_side, tokenizer.pad_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = {}\n\nfor split in dataset.keys():\n    tokenized_dataset[split] = dataset[split].map(\n        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True\n    )\n    \n\ntokenized_dataset[\"train\"], tokenized_dataset[\"test\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_ID,\n    num_labels=NUM_CLASSES,\n    load_in_8bit=True,\n)\nprint(model.config.pad_token_id)\nmodel.config.pad_token_id = model.config.eos_token_id\nprint(model.config.pad_token_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import prepare_model_for_int8_training\n\nmodel = prepare_model_for_int8_training(model)\n\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, TaskType, get_peft_model\n\nlora_config = LoraConfig(\n    r=R,\n    lora_alpha=LORA_ALPHA,\n    lora_dropout=LORA_DROPOUT,\n    task_type=TaskType.SEQ_CLS,\n    target_modules='all-linear'\n)\nlora_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_model = get_peft_model(model, lora_config)\nlora_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_model.print_trainable_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (predictions == labels).mean()}\n\ntrainer = Trainer(\n    model=lora_model,\n    args=TrainingArguments(\n        output_dir=\"./data/\",\n        learning_rate=2e-5,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        num_train_epochs=EPOCHS,\n        weight_decay=0.01,\n        load_best_model_at_end=True,\n        logging_steps=10,\n        report_to=\"none\"\n    ),\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Evaluating the Model Before Training!\")\ntrainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training the Model\")\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Evaluating the trained model\")\ntrainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Saving the model!\")\nlora_model.save_pretrained('fine-tuned-model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nclf = pipeline(\"text-classification\", lora_model, tokenizer=MODEL_ID)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv(f\"/kaggle/input/nlp-getting-started/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n\ndisplay(test_df.head())\ndisplay(sample_submission.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\npredictions = []\n\nprint(\"Making prediction on test dataset...\")\n\nfor text in tqdm(test_df['text'].values):\n    prediction = clf(text)\n    prediction = int(prediction[0]['label'].split('_')[1])\n    predictions.append(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['target'] = predictions\n\nsample_submission.to_csv(f'submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}